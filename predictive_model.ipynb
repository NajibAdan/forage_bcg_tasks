{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictive Model\n",
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder, Normalizer,MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score,accuracy_score,precision_score,recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>channel_sales</th>\n",
       "      <th>cons_12m</th>\n",
       "      <th>cons_gas_12m</th>\n",
       "      <th>cons_last_month</th>\n",
       "      <th>date_activ</th>\n",
       "      <th>date_end</th>\n",
       "      <th>date_modif_prod</th>\n",
       "      <th>date_renewal</th>\n",
       "      <th>forecast_cons_12m</th>\n",
       "      <th>...</th>\n",
       "      <th>peak_mid_peak_var_max_monthly_diff</th>\n",
       "      <th>off_peak_mid_peak_var_max_monthly_diff</th>\n",
       "      <th>off_peak_peak_fix_max_monthly_diff</th>\n",
       "      <th>peak_mid_peak_fix_max_monthly_diff</th>\n",
       "      <th>off_peak_mid_peak_fix_max_monthly_diff</th>\n",
       "      <th>tenure</th>\n",
       "      <th>months_activ</th>\n",
       "      <th>months_to_end</th>\n",
       "      <th>months_modif_prod</th>\n",
       "      <th>months_renewal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24011ae4ebbe3035111d65fa7c15bc57</td>\n",
       "      <td>foosdfpfkusacimwkcsosbicdxkicaua</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.739944</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2013-06-15</td>\n",
       "      <td>2016-06-15</td>\n",
       "      <td>2015-11-01</td>\n",
       "      <td>2015-06-23</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.034219</td>\n",
       "      <td>0.058257</td>\n",
       "      <td>18.590255</td>\n",
       "      <td>7.450670</td>\n",
       "      <td>26.040925</td>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>d29c2c54acc38ff3c0614d0a653813dd</td>\n",
       "      <td>MISSING</td>\n",
       "      <td>3.668479</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2009-08-21</td>\n",
       "      <td>2016-08-30</td>\n",
       "      <td>2009-08-21</td>\n",
       "      <td>2015-08-31</td>\n",
       "      <td>2.280920</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007124</td>\n",
       "      <td>0.149609</td>\n",
       "      <td>44.311375</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>44.311375</td>\n",
       "      <td>7</td>\n",
       "      <td>76</td>\n",
       "      <td>7</td>\n",
       "      <td>76</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>764c75f661154dac3a6c254cd082ea7d</td>\n",
       "      <td>foosdfpfkusacimwkcsosbicdxkicaua</td>\n",
       "      <td>2.736397</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2010-04-16</td>\n",
       "      <td>2016-04-16</td>\n",
       "      <td>2010-04-16</td>\n",
       "      <td>2015-04-17</td>\n",
       "      <td>1.689841</td>\n",
       "      <td>...</td>\n",
       "      <td>0.088421</td>\n",
       "      <td>0.170512</td>\n",
       "      <td>44.385450</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>44.385450</td>\n",
       "      <td>6</td>\n",
       "      <td>68</td>\n",
       "      <td>3</td>\n",
       "      <td>68</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bba03439a292a1e166f80264c16191cb</td>\n",
       "      <td>lmkebamcaaclubfxadlmueccxoimlema</td>\n",
       "      <td>3.200029</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2010-03-30</td>\n",
       "      <td>2016-03-30</td>\n",
       "      <td>2010-03-30</td>\n",
       "      <td>2015-03-31</td>\n",
       "      <td>2.382089</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.151210</td>\n",
       "      <td>44.400265</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>44.400265</td>\n",
       "      <td>6</td>\n",
       "      <td>69</td>\n",
       "      <td>2</td>\n",
       "      <td>69</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>149d57cf92fc41cf94415803a877cb4b</td>\n",
       "      <td>MISSING</td>\n",
       "      <td>3.646011</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.721811</td>\n",
       "      <td>2010-01-13</td>\n",
       "      <td>2016-03-07</td>\n",
       "      <td>2010-01-13</td>\n",
       "      <td>2015-03-09</td>\n",
       "      <td>2.650065</td>\n",
       "      <td>...</td>\n",
       "      <td>0.030773</td>\n",
       "      <td>0.051309</td>\n",
       "      <td>16.275263</td>\n",
       "      <td>8.137629</td>\n",
       "      <td>24.412893</td>\n",
       "      <td>6</td>\n",
       "      <td>71</td>\n",
       "      <td>2</td>\n",
       "      <td>71</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 78 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 id                     channel_sales  \\\n",
       "0  24011ae4ebbe3035111d65fa7c15bc57  foosdfpfkusacimwkcsosbicdxkicaua   \n",
       "1  d29c2c54acc38ff3c0614d0a653813dd                           MISSING   \n",
       "2  764c75f661154dac3a6c254cd082ea7d  foosdfpfkusacimwkcsosbicdxkicaua   \n",
       "3  bba03439a292a1e166f80264c16191cb  lmkebamcaaclubfxadlmueccxoimlema   \n",
       "4  149d57cf92fc41cf94415803a877cb4b                           MISSING   \n",
       "\n",
       "   cons_12m  cons_gas_12m  cons_last_month  date_activ    date_end  \\\n",
       "0  0.000000      4.739944         0.000000  2013-06-15  2016-06-15   \n",
       "1  3.668479      0.000000         0.000000  2009-08-21  2016-08-30   \n",
       "2  2.736397      0.000000         0.000000  2010-04-16  2016-04-16   \n",
       "3  3.200029      0.000000         0.000000  2010-03-30  2016-03-30   \n",
       "4  3.646011      0.000000         2.721811  2010-01-13  2016-03-07   \n",
       "\n",
       "  date_modif_prod date_renewal  forecast_cons_12m  ...  \\\n",
       "0      2015-11-01   2015-06-23           0.000000  ...   \n",
       "1      2009-08-21   2015-08-31           2.280920  ...   \n",
       "2      2010-04-16   2015-04-17           1.689841  ...   \n",
       "3      2010-03-30   2015-03-31           2.382089  ...   \n",
       "4      2010-01-13   2015-03-09           2.650065  ...   \n",
       "\n",
       "   peak_mid_peak_var_max_monthly_diff  off_peak_mid_peak_var_max_monthly_diff  \\\n",
       "0                            0.034219                                0.058257   \n",
       "1                            0.007124                                0.149609   \n",
       "2                            0.088421                                0.170512   \n",
       "3                            0.000000                                0.151210   \n",
       "4                            0.030773                                0.051309   \n",
       "\n",
       "   off_peak_peak_fix_max_monthly_diff  peak_mid_peak_fix_max_monthly_diff  \\\n",
       "0                           18.590255                            7.450670   \n",
       "1                           44.311375                            0.000000   \n",
       "2                           44.385450                            0.000000   \n",
       "3                           44.400265                            0.000000   \n",
       "4                           16.275263                            8.137629   \n",
       "\n",
       "   off_peak_mid_peak_fix_max_monthly_diff  tenure months_activ  months_to_end  \\\n",
       "0                               26.040925       3           30              5   \n",
       "1                               44.311375       7           76              7   \n",
       "2                               44.385450       6           68              3   \n",
       "3                               44.400265       6           69              2   \n",
       "4                               24.412893       6           71              2   \n",
       "\n",
       "   months_modif_prod  months_renewal  \n",
       "0                  2               6  \n",
       "1                 76               4  \n",
       "2                 68               8  \n",
       "3                 69               9  \n",
       "4                 71               9  \n",
       "\n",
       "[5 rows x 78 columns]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('cleaned_and_engineered_data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'channel_sales', 'cons_12m', 'cons_gas_12m', 'cons_last_month',\n",
       "       'date_activ', 'date_end', 'date_modif_prod', 'date_renewal',\n",
       "       'forecast_cons_12m', 'forecast_cons_year', 'forecast_discount_energy',\n",
       "       'forecast_meter_rent_12m', 'forecast_price_energy_off_peak',\n",
       "       'forecast_price_energy_peak', 'forecast_price_pow_off_peak', 'has_gas',\n",
       "       'imp_cons', 'margin_gross_pow_ele', 'margin_net_pow_ele', 'nb_prod_act',\n",
       "       'net_margin', 'num_years_antig', 'origin_up', 'pow_max',\n",
       "       'mean_year_price_p1_var', 'mean_year_price_p2_var',\n",
       "       'mean_year_price_p3_var', 'mean_year_price_p1_fix',\n",
       "       'mean_year_price_p2_fix', 'mean_year_price_p3_fix',\n",
       "       'mean_year_price_p1', 'mean_year_price_p2', 'mean_year_price_p3',\n",
       "       'mean_6m_price_p1_var', 'mean_6m_price_p2_var', 'mean_6m_price_p3_var',\n",
       "       'mean_6m_price_p1_fix', 'mean_6m_price_p2_fix', 'mean_6m_price_p3_fix',\n",
       "       'mean_6m_price_p1', 'mean_6m_price_p2', 'mean_6m_price_p3',\n",
       "       'mean_3m_price_p1_var', 'mean_3m_price_p2_var', 'mean_3m_price_p3_var',\n",
       "       'mean_3m_price_p1_fix', 'mean_3m_price_p2_fix', 'mean_3m_price_p3_fix',\n",
       "       'mean_3m_price_p1', 'mean_3m_price_p2', 'mean_3m_price_p3', 'churn',\n",
       "       'modif_after_activ', 'days_to_end', 'offpeak_diff_dec_january_energy',\n",
       "       'offpeak_diff_dec_january_power', 'peak_diff_dec_january_energy',\n",
       "       'peak_diff_dec_january_power', 'midpeak_diff_dec_january_energy',\n",
       "       'midpeak_diff_dec_january_power', 'off_peak_peak_var_mean_diff',\n",
       "       'peak_mid_peak_var_mean_diff', 'off_peak_mid_peak_var_mean_diff',\n",
       "       'off_peak_peak_fix_mean_diff', 'peak_mid_peak_fix_mean_diff',\n",
       "       'off_peak_mid_peak_fix_mean_diff', 'off_peak_peak_var_max_monthly_diff',\n",
       "       'peak_mid_peak_var_max_monthly_diff',\n",
       "       'off_peak_mid_peak_var_max_monthly_diff',\n",
       "       'off_peak_peak_fix_max_monthly_diff',\n",
       "       'peak_mid_peak_fix_max_monthly_diff',\n",
       "       'off_peak_mid_peak_fix_max_monthly_diff', 'tenure', 'months_activ',\n",
       "       'months_to_end', 'months_modif_prod', 'months_renewal'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop([\"date_activ\",\"date_end\",\"date_modif_prod\",\"date_renewal\",\"id\",\"churn\"],axis=1)\n",
    "Y = df['churn']\n",
    "cols_norm = ['cons_12m','cons_gas_12m','cons_last_month','forecast_cons_12m','forecast_cons_year','forecast_discount_energy',\n",
    "            'forecast_meter_rent_12m','forecast_price_pow_off_peak','imp_cons','margin_gross_pow_ele','margin_net_pow_ele',\n",
    "            'net_margin','pow_max','modif_after_activ']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Design\n",
    "I created a function that will test the model we create and print out the performance.To test the performance of the model I'll be using the precision, recall and accuracy scores.\n",
    "\n",
    "For our prediction model, I'll be using the Random Forest Classifier which is an `ensemble` algorithms because internally the `Forest` refers to a collection of `Decision Trees` which are tree-based learning algorithms.\n",
    "Some additional advantages of the random forest classifier include:\n",
    "\n",
    "- The random forest uses a rule-based approach instead of a distance calculation and so features do not need to be scaled\n",
    "- It is able to handle non-linear parameters better than linear based models\n",
    "\n",
    "On the flip side, some disadvantages of the random forest classifier include:\n",
    "\n",
    "- The computational power needed to train a random forest on a large dataset is high, since we need to build a whole ensemble of estimators.\n",
    "- Training time can be longer due to the increased complexity and size of thee ensemble. \n",
    "\n",
    "The first thing we want to do is split our dataset into training and test samples. The reason why we do this, is so that we can simulate a real life situation by generating predictions for our test sample, without showing the predictive model these data points. This gives us the ability to see how well our model is able to generalise to new data, which is critical.\n",
    "\n",
    "A typical % to dedicate to testing is between 20-30, for this example we will use a 80-20% split between train and test respectively.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(X,Y):\n",
    "    X_train, X_test,y_train, y_test = train_test_split(X,Y,test_size=0.20, random_state=42)\n",
    "    model = RandomForestClassifier(1000)\n",
    "    model.fit(X_train,y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    print('Precision: %.3f' % precision_score(y_test, y_pred))\n",
    "    print('Recall: %.3f' % recall_score(y_test, y_pred))\n",
    "    print('F1: %.3f' % f1_score(y_test, y_pred))\n",
    "    print('Accuracy: %.3f' % accuracy_score(y_test, y_pred))\n",
    "    print('-'*20)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'll also encode categorical features into numerical representations since our model cannot accept categorical or `string` values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.895\n",
      "Recall: 0.057\n",
      "F1: 0.107\n",
      "Accuracy: 0.903\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "def transform_categorical(X):\n",
    "    '''\n",
    "    Encodes categorical columns\n",
    "    '''\n",
    "    X_copy = X.copy()\n",
    "    categories = (X_copy.dtypes ==\"object\")\n",
    "    cat_cols = list(categories[categories].index)\n",
    "    label_encoder = LabelEncoder()\n",
    "    for col in cat_cols:\n",
    "        X_copy[col] = label_encoder.fit_transform(X[col])\n",
    "    return X_copy\n",
    "\n",
    "def normalize_data(X,cols_to_norm):\n",
    "    scaler = MinMaxScaler()\n",
    "    X_copy = X.copy()\n",
    "    X_copy[cols_to_norm] = scaler.fit_transform(X[cols_to_norm])\n",
    "    return X_copy\n",
    "x_2 = transform_categorical(X)\n",
    "x_2 = normalize_data(x_2,cols_norm)\n",
    "run_experiment(x_2,Y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation:\n",
    "\n",
    "We are going to use 3 metrics to evaluate performance:\n",
    "\n",
    "- Accuracy = the ratio of correctly predicted observations to the total observations\n",
    "- Precision = the ability of the classifier to not label a negative sample as positive\n",
    "- Recall = the ability of the classifier to find all the positive samples\n",
    "\n",
    "The reason why we are using these three metrics is because a simple accuracy is not always a good measure to use.\n",
    "\n",
    "- Looking at the accuracy score, this is very misleading! Hence the use of precision and recall is important. The accuracy score is high, but it does not tell us the whole story.\n",
    "- Looking at the precision score, this shows us a score of 0.89 which is not bad, but could be improved.\n",
    "- However, the recall shows us that the classifier has a very poor ability to identify positive samples. This would be the main concern for improving this model!\n",
    "\n",
    "So overall, we're able to very accurately identify clients that do not churn, but we are not able to predict cases where clients do churn! What we are seeing is that a high % of clients are being identified as not churning when they should be identified as churning. This in turn tells me that the current set of features are not discriminative enough to clearly distinguish between churners and non-churners. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
